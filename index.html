<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ù…Ø³Ø¨Ø­Ø© Whisper - Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ù†Øµ</title>
    <style>
        :root { --primary: #10b981; --bg: #0f172a; --card-bg: #1e293b; --text: #f8fafc; }
        body { font-family: sans-serif; background-color: var(--bg); color: var(--text); padding: 20px; display: flex; flex-direction: column; align-items: center; min-height: 100vh; margin: 0; }
        
        /* Ù…Ø±Ø¨Ø¹ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± */
        #monitor-box {
            width: 90%; max-width: 600px; background: #000; border: 2px solid var(--primary);
            padding: 15px; border-radius: 12px; margin-bottom: 20px; min-height: 60px;
            color: #adff2f; font-family: monospace; font-size: 1.1rem; text-align: center;
            box-shadow: inset 0 0 10px rgba(16, 185, 129, 0.2);
        }

        #status-container { background: #334155; padding: 10px; border-radius: 8px; margin-bottom: 20px; width: 90%; max-width: 600px; text-align: center; }
        .grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(140px, 1fr)); gap: 10px; width: 100%; max-width: 600px; }
        .card { background: var(--card-bg); padding: 20px; border-radius: 15px; text-align: center; border: 2px solid transparent; transition: 0.3s; }
        .count { font-size: 2.5rem; font-weight: bold; color: var(--primary); }
        .flash-active { animation: flash 0.5s ease-out; }
        @keyframes flash { 0% { background: var(--primary); transform: scale(1.05); } 100% { background: var(--card-bg); transform: scale(1); } }
        
        .controls { margin-top: 20px; display: flex; gap: 10px; }
        button { padding: 15px 25px; border-radius: 30px; border: none; font-weight: bold; cursor: pointer; }
        #record-btn { background: var(--primary); color: white; }
        #record-btn.recording { background: #ef4444; }
        #record-btn:disabled { opacity: 0.3; }
    </style>
</head>
<body>

    <h2 style="color: var(--primary);">Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø°ÙƒØ± Ø§Ù„Ø°ÙƒÙŠ</h2>

    <div id="monitor-box">Ø§Ù†ØªØ¸Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬...</div>

    <div id="status-container">
        <div id="status-text" style="color: #fbbf24;">Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Whisper AI...</div>
        <div id="progress-bar" style="font-size: 0.8rem;"></div>
    </div>

    <div class="grid" id="dhikr-grid">
        <div class="card" data-phrase="Ø§Ø³ØªØºÙØ± Ø§Ù„Ù„Ù‡">
            <div>Ø£Ø³ØªØºÙØ± Ø§Ù„Ù„Ù‡</div>
            <div class="count">0</div>
        </div>
        <div class="card" data-phrase="Ø³Ø¨Ø­Ø§Ù† Ø§Ù„Ù„Ù‡">
            <div>Ø³Ø¨Ø­Ø§Ù† Ø§Ù„Ù„Ù‡</div>
            <div class="count">0</div>
        </div>
        <div class="card" data-phrase="Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡">
            <div>Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡</div>
            <div class="count">0</div>
        </div>
    </div>

    <div class="controls">
        <button id="record-btn" disabled>Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„...</button>
        <button onclick="location.reload()" style="background:#475569; color:white;">ØªØ­Ø¯ÙŠØ«</button>
    </div>

    <script type="module">
        import { pipeline } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.6.0';

        let transcriber;
        let isRecording = false;
        let audioCtx;
        let stream;

        const monitor = document.getElementById('monitor-box');
        const status = document.getElementById('status-text');
        const btn = document.getElementById('record-btn');

        // 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø¨Ø°ÙƒØ§Ø¡
        async function init() {
            try {
                transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny', {
                    progress_callback: (p) => {
                        if (p.status === 'progress') 
                            document.getElementById('progress-bar').innerText = `ØªÙ… ØªØ­Ù…ÙŠÙ„ ${Math.round(p.loaded)}%`;
                    }
                });
                status.innerText = "âœ… Ø¬Ø§Ù‡Ø² ØªÙ…Ø§Ù…Ø§Ù‹";
                status.style.color = "#10b981";
                monitor.innerText = "Ø§Ø¶ØºØ· (Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ³Ø¬ÙŠÙ„) ÙˆØªØ­Ø¯Ø«";
                btn.disabled = false;
                btn.innerText = "ğŸ¤ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ³Ø¬ÙŠÙ„";
            } catch (e) {
                status.innerText = "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„";
            }
        }
        init();

        // 2. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„
        btn.onclick = async () => {
            if (isRecording) {
                isRecording = false;
                btn.innerText = "ğŸ¤ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ³Ø¬ÙŠÙ„";
                btn.classList.remove('recording');
                if (stream) stream.getTracks().forEach(t => t.stop());
                return;
            }
            startWorker();
        };

        async function startWorker() {
            isRecording = true;
            btn.innerText = "ğŸ›‘ ØªÙˆÙ‚Ù";
            btn.classList.add('recording');
            monitor.innerText = "Ø£Ø³Ù…Ø¹Ùƒ Ø§Ù„Ø¢Ù†... ØªÙƒÙ„Ù…";

            stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            audioCtx = new AudioContext({ sampleRate: 16000 });
            
            const recorder = new MediaRecorder(stream);
            let chunks = [];

            recorder.ondataavailable = e => chunks.push(e.data);
            recorder.onstop = async () => {
                const blob = new Blob(chunks, { type: 'audio/wav' });
                chunks = [];
                if (isRecording) {
                    analyze(blob);
                    recorder.start(); 
                    setTimeout(() => { if(recorder.state === 'recording') recorder.stop(); }, 4000);
                }
            };

            recorder.start();
            setTimeout(() => { if(recorder.state === 'recording') recorder.stop(); }, 4000);
        }

        // 3. ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØª ÙˆÙ…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª
        async function analyze(blob) {
            const buffer = await blob.arrayBuffer();
            const decoded = await audioCtx.decodeAudioData(buffer);
            const audio = decoded.getChannelData(0);

            const result = await transcriber(audio, { language: 'arabic', task: 'transcribe' });
            let text = result.text.trim();
            
            // Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ ÙÙŠ Ù…Ø±Ø¨Ø¹ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©
            monitor.innerText = "Ø³Ù…Ø¹Øª: " + text;

            const cleanText = normalize(text);
            const cards = document.querySelectorAll('.card');

            cards.forEach(card => {
                const phrase = normalize(card.getAttribute('data-phrase'));
                // Ù†Ø³ØªØ®Ø¯Ù… Regex Ù„Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª ÙÙŠ Ø§Ù„Ø¬Ù…Ù„Ø©
                const regex = new RegExp(phrase, "g");
                const matches = (cleanText.match(regex) || []).length;
                
                if (matches > 0) {
                    const countEl = card.querySelector('.count');
                    countEl.innerText = parseInt(countEl.innerText) + matches;
                    card.classList.remove('flash-active');
                    void card.offsetWidth;
                    card.classList.add('flash-active');
                }
            });
        }

        function normalize(t) {
            return t.replace(/[Ø¥Ø£Ø¢Ø§]/g, "Ø§").replace(/Ø©/g, "Ù‡").replace(/[ÙÙ‹ÙÙŒÙÙÙ’Ù‘]/g, "").replace(/\./g, "").trim();
        }
    </script>
</body>
</html>
